import asyncio
import os
from dotenv import load_dotenv
from fastapi import FastAPI
from pydantic import BaseModel
from typing import List, Dict, Optional

from modules.base_module import BaseModule
from tools.prompts.text_prompt import text_prompt
from utils.llms import Kimi
from utils.utils import send_chat_prompts, extract_value_from_prompt

# åŠ è½½ .env é…ç½®
load_dotenv(override=True)
MODEL_NAME = os.getenv('DeepSeek')
print(os.getenv('MODEL_NAME'))


# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(title="TextGenerator API")

# è¯·æ±‚ä½“æ•°æ®æ¨¡å‹
class GenerateTextRequest(BaseModel):
    dialogues: List[Dict[str, str]]
    description: List[Dict[str, str]]

class TextGenerator(BaseModule):
    def __init__(self, llm=Kimi()):
        super().__init__(llm=llm)
        self.history: List[dict] = []            # å­˜çº¯ role+content
        self.character_name: Optional[str] = None

    async def generate_text(self, dialogues, description, character_name: Optional[str] = None):
        # â€”â€” 1. è·å–æœ‰æ•ˆè§’è‰²æè¿°ï¼ˆæ”¯æŒè½®æ¢ï¼‰
        print("ğŸ§ª ä½¿ç”¨è§’è‰²æè¿°ï¼š", description)

        # â€”â€” 2. æŠ½è§’è‰²å
        if self.character_name is None and character_name:
            self.character_name = character_name

        # â€”â€” 3. æ„å»º system prompt
        desc_text = self.transfer_data_to_prompt(description)
        system_content = (
            text_prompt["SYSTEM_PROMPT"].strip()
            + "\n\n**Persona**:\n" + desc_text
        )

        # â€”â€” 4. åˆå¹¶æ‰€æœ‰ dialogues ä¸ºä¸€å¥ user_inputï¼ˆä¹Ÿå¯æŒ‰æ¡å¡ï¼Œè§†ä½ éœ€æ±‚ï¼‰
        user_input = "\n".join(d["Input"].strip() for d in dialogues if d.get("Input"))

        # â€”â€” 5. å¼€å§‹æ„å»ºæœ¬æ¬¡è¯·æ±‚çš„ messages åˆ—è¡¨
        msgs: List[dict] = [
            {"role": "system", "content": system_content}
        ]
        # é™åˆ¶å†å²é•¿åº¦ï¼Œå‡è®¾ä¿ç•™æœ€æ–° 10 æ¡
        #TODOï¼šç”¨redisæ¥ä¿å­˜è®°å½•
        if len(self.history) > 10:
            self.history = self.history[-10:]
        msgs.extend(self.history)

        # åŠ å…¥æœ¬è½®ç”¨æˆ·
        msgs.append({"role": "user", "content": user_input})

        # **åªæœ‰æœ€åä¸€æ¡**å¸¦ partial/nameï¼Œç¬¦åˆ Moonshot Partial Mode
        msgs.append({
            "partial": True,
            "role": "assistant",
            "name": self.character_name,
            "content": ""
        })

        # â€”â€” 6. å‘é€ç»™ Kimi
        response = await self.llm.chat(msgs, temperature=0.3, prefix="Overall")

        # â€”â€” 7. æ›´æ–°çº¯å‡€å†å²
        self.history.append({"role": "user", "content": user_input})
        self.history.append({"role": "assistant", "content": response})

        # â€”â€” 8. è¿”å›æœ€ç»ˆå›ç­”
        return self.extract_content_from_response(response)

# åˆ›å»ºè·¯ç”±ï¼šPOST /generate-text
@app.post("/generate-text")
async def generate_text_api(request: GenerateTextRequest):
    generator = TextGenerator()
    result = await generator.generate_text(request.dialogues, request.description)
    return {"result": result}

# æµ‹è¯•å…¥å£ï¼ˆä»…è°ƒè¯•ç”¨ï¼‰
if __name__ == '__main__':
    import asyncio
    from tools.character.manager import CharacterPromptManager
    from utils.redis import r  # ä½ ä¹‹å‰å®šä¹‰å¥½çš„ redis å®ä¾‹

    # æ¨¡æ‹Ÿè¯·æ±‚è¾“å…¥
    user_id = 87  # ä½ å¯ä»¥æ ¹æ®æµ‹è¯•éœ€è¦æ¢æˆå…¶ä»–æ•°å­—
    dialogues = [{"Input": "How are you today?"}]
    description_raw = "0"  # éæ³•æè¿°ï¼Œè§¦å‘é»˜è®¤è½®æ¢è§’è‰²

    # åˆ›å»ºé»˜è®¤è§’è‰²ç®¡ç†å™¨ï¼Œå¹¶ç”Ÿæˆè§’è‰²æè¿°
    manager = CharacterPromptManager(user_id=user_id, redis_client=r)
    description = manager.get_character_description(description_raw)
    character_name = manager._extract_name(description)

    # å®ä¾‹åŒ–æ–‡æœ¬ç”Ÿæˆå™¨å¹¶ç”Ÿæˆæ–‡æœ¬
    text_generator = TextGenerator()
    result = asyncio.run(text_generator.generate_text(dialogues, description, character_name=character_name))

    # æ‰“å°è¾“å‡º
    print(dialogues)
    print("âœ… æ¨¡å‹è¾“å‡ºï¼š")
    print(result)
